# Comparative analysis of Graph Clustering Algorithms

<p align="center">
  <img width="360" src="img.png">
</p>

<p align="justify">
Graph clustering refers to the methods by which we can do a grouping of data in the form of graphs. It has received a lot of attention from the research community in the recent years. In this project, we have done a detailed study on graph clustering, the methods by which they are classified, and studied certain algorithms that play a vital role in clustering. We have performed and shown different results of the popular clustering algorithms. These graph clustering algorithms can be used in various fields, including bioinformatics, community detection, computer network analysis, social network analysis etc. We studied the following algorithms:

- Minimum Spanning Tree(MST) based clustering algorithm
- Hierarchical Agglomerative Clustering algorithm
- Markov clustering algorithm
- Spectral Clustering
- Shared Nearest Neighbor(SNN) Clustering
- Betweenness Centrality
- Maximal Clique Enumeration 
- Kernel K-means clustering 
<p/>
<p align="justify">
Many graph clustering techniques have been developed in the past. Each algorithm has its own set of advantages and disadvantages. Because of its superiority, Markov Clustering has been highlighted frequently nowadays. However, it is biased towards discovering a large number of extremely small clusters and fails to detect many larger clusters. Experiments on data sets have shown that the MST based Clustering and Spectral Clustering method outperforms the kmeans clustering algorithm by a wide margin. The drawback of MST based Clustering is that they have high computational complexity. Spectral Clustering algorithm is effective for different shapes of cluster and for the sparse data it is computationally faster. Hierarchical Agglomerative Clustering is quite straightforward and easy to understand. Also it is not necessary to know the number of clusters ahead of time in this algorithm but the disadvantage of this approach is that it is too slow when working with large datasets. Shared Nearest Neighbor(SNN) Clustering with the functioning of Jarvis Patrick Clustering algorithm is exceptionally good. In Betweenness Centrality we have seen that the role of centrality and shortest path passing through the node or vertex helped us get the clusters in an easier way. The Bron and Kerbosch Algorithm made it possible to find the maximal cliques followed by the Kernel k means which helped us calculate complex clusters using inplace of distance measures of k-means.
<p/>
